{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09Hxs6Rb6gzf",
    "outputId": "ac096334-98c0-4a8e-bd8f-b7217fbc5916"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pythainlp\n",
      "  Downloading pythainlp-5.0.1-py3-none-any.whl (17.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.9/17.9 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from pythainlp) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (2024.2.2)\n",
      "Installing collected packages: pythainlp\n",
      "Successfully installed pythainlp-5.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pythainlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xa1JmdON4tUz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.metrics import classification_report\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "3QZc639B4uzW",
    "tags": []
   },
   "outputs": [],
   "source": [
    "pos_text = (\"C:/Users/Gumpun/Sentiment-Analysis-System-for-Consumer-Products/DataReviewProductThai/Positive.csv\")\n",
    "neg_text = (\"C:/Users/Gumpun/Sentiment-Analysis-System-for-Consumer-Products/DataReviewProductThai/Negative.csv\")\n",
    "neu_text = (\"C:/Users/Gumpun/Sentiment-Analysis-System-for-Consumer-Products/DataReviewProductThai/Neutrally.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "yLj2ndbi4690",
    "outputId": "f3097c1f-83d0-45a6-950d-ba505c562675",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Message</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>M***k</td>\n",
       "      <td>ใส่สบาย ผ้าบางตามราคา</td>\n",
       "      <td>Neutrally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>****9</td>\n",
       "      <td>จัดส่งรวดเร็วมาก บรรจุหีบห่อดี คุณภาพสินค้าตาม...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>N***�</td>\n",
       "      <td>สมราคา</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Yew C.</td>\n",
       "      <td>โฆษณาเกินไปครับ ไม่ได้ออก ยอมซักมือดีฟ่า</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>Atchadaporn P.</td>\n",
       "      <td>สินค้าคุ้มค่ามากกกกกกกกกกกกก จัดส่งรวดเร็ว คุณ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>กีระติ แ.</td>\n",
       "      <td>สั่งรอบที่สองชุด ทำไมได้อุปกรณ์เสริมมาชุดเดียว...</td>\n",
       "      <td>Neutrally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>N***.</td>\n",
       "      <td>สินค้าไม่มีกล่อง แต่เป็นการแพ็คของด้วยบับโบ้ ส...</td>\n",
       "      <td>Neutrally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>*******048</td>\n",
       "      <td>เล็กไปนิดหน่อย</td>\n",
       "      <td>Neutrally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>วีกิจ ธ.</td>\n",
       "      <td>เป็นสินค้าคุณภาพดีเหมาะสมกับราคาสีสันย้อมดีใส่...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>Ketsarin A.</td>\n",
       "      <td>วัสดุเนื้อไม่ค่อยดีเท่าไร</td>\n",
       "      <td>Neutrally</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                User                                            Message  \\\n",
       "1230           M***k                              ใส่สบาย ผ้าบางตามราคา   \n",
       "451            ****9  จัดส่งรวดเร็วมาก บรรจุหีบห่อดี คุณภาพสินค้าตาม...   \n",
       "995            N***�                                             สมราคา   \n",
       "399           Yew C.           โฆษณาเกินไปครับ ไม่ได้ออก ยอมซักมือดีฟ่า   \n",
       "637   Atchadaporn P.  สินค้าคุ้มค่ามากกกกกกกกกกกกก จัดส่งรวดเร็ว คุณ...   \n",
       "...              ...                                                ...   \n",
       "7          กีระติ แ.  สั่งรอบที่สองชุด ทำไมได้อุปกรณ์เสริมมาชุดเดียว...   \n",
       "1241           N***.  สินค้าไม่มีกล่อง แต่เป็นการแพ็คของด้วยบับโบ้ ส...   \n",
       "948       *******048                                     เล็กไปนิดหน่อย   \n",
       "762         วีกิจ ธ.  เป็นสินค้าคุณภาพดีเหมาะสมกับราคาสีสันย้อมดีใส่...   \n",
       "1215     Ketsarin A.                          วัสดุเนื้อไม่ค่อยดีเท่าไร   \n",
       "\n",
       "      Sentiment  \n",
       "1230  Neutrally  \n",
       "451    Positive  \n",
       "995    Positive  \n",
       "399    Negative  \n",
       "637    Positive  \n",
       "...         ...  \n",
       "7     Neutrally  \n",
       "1241  Neutrally  \n",
       "948   Neutrally  \n",
       "762    Positive  \n",
       "1215  Neutrally  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_df = pd.read_csv(pos_text, delimiter=',', encoding='utf-8').dropna()\n",
    "neg_df = pd.read_csv(neg_text, delimiter=',', encoding='utf-8').dropna()\n",
    "neu_df = pd.read_csv(neu_text, delimiter=',', encoding='utf-8').dropna()\n",
    "\n",
    "data = pd.concat([pos_df, neg_df, neu_df])\n",
    "data.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "bKoP6LrN5FE_",
    "outputId": "51c4a22b-4301-4aa5-88a7-fdaf53246e63",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Message</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>R***.</td>\n",
       "      <td>เล็ก</td>\n",
       "      <td>Neutrally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>Donlaya R.</td>\n",
       "      <td>ได้รับ ของ แล้ว นะค   สิน ค้าส่ง ไว มาก ๆ ค่ะ ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>งงอ๋อ'อ ฯ.</td>\n",
       "      <td>กล่อง มี รอย ตำหนิ นิดห่อย ครับ   แต่ ของ ตรง ...</td>\n",
       "      <td>Neutrally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>Wannee Y.</td>\n",
       "      <td>มาถึง กระจ เ เตก ใช้ไม่ด ค่ะ</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>ฐานิดา ก.</td>\n",
       "      <td>คอกลม ทำให้ สบาย   ลวดาย การ์ตูน น่ารัก มาก</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>*******469</td>\n",
       "      <td>ไม่ ตรง ปก</td>\n",
       "      <td>Neutrally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>ดามร ล.</td>\n",
       "      <td>ราค ถูก   แต่ ผ้า บาง มาก</td>\n",
       "      <td>Neutrally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>ธนพร ป.</td>\n",
       "      <td>ได้รับ ของ ตามที่ ได้ แจ้ง ไว้   กระท สวย   แพ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>*******605</td>\n",
       "      <td>สี ไม่ ตรง ปก ครับ สั่ง สี ดำ</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>เอก</td>\n",
       "      <td>คุณภาพ ตาม ราค นั่แหละ ครับ อย่า คาดหวัง เยอะ ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            User                                            Message  Sentiment\n",
       "284        R***.                                               เล็ก  Neutrally\n",
       "726   Donlaya R.  ได้รับ ของ แล้ว นะค   สิน ค้าส่ง ไว มาก ๆ ค่ะ ...   Positive\n",
       "1359  งงอ๋อ'อ ฯ.  กล่อง มี รอย ตำหนิ นิดห่อย ครับ   แต่ ของ ตรง ...  Neutrally\n",
       "931    Wannee Y.                       มาถึง กระจ เ เตก ใช้ไม่ด ค่ะ   Negative\n",
       "1237   ฐานิดา ก.        คอกลม ทำให้ สบาย   ลวดาย การ์ตูน น่ารัก มาก   Positive\n",
       "1149  *******469                                         ไม่ ตรง ปก  Neutrally\n",
       "444      ดามร ล.                          ราค ถูก   แต่ ผ้า บาง มาก  Neutrally\n",
       "1409     ธนพร ป.  ได้รับ ของ ตามที่ ได้ แจ้ง ไว้   กระท สวย   แพ...   Positive\n",
       "570   *******605                      สี ไม่ ตรง ปก ครับ สั่ง สี ดำ   Positive\n",
       "953          เอก  คุณภาพ ตาม ราค นั่แหละ ครับ อย่า คาดหวัง เยอะ ...   Negative"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# สร้างฟังก์ชันสำหรับการลบอักขระที่ซ้ำกันในแต่ละคำเท่านั้น\n",
    "def remove_duplicate_chars(text):\n",
    "    if isinstance(text, str):  # ตรวจสอบว่าข้อความไม่ใช่ NaN\n",
    "        unique_words = []\n",
    "        words = word_tokenize(text)\n",
    "        for word in words:\n",
    "            unique_word = ''\n",
    "            for char in word:\n",
    "                if char not in unique_word:\n",
    "                    unique_word += char\n",
    "            unique_words.append(unique_word)\n",
    "        return ' '.join(unique_words)\n",
    "    else:\n",
    "        return text  # ส่งค่า NaN กลับหากเป็น NaN\n",
    "\n",
    "# ใช้ฟังก์ชัน `remove_duplicate_chars` เพื่อ Tokenize และลบคำที่ซ้ำ\n",
    "data['Message'] = data['Message'].apply(remove_duplicate_chars)\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "poGuNoof62Ym",
    "outputId": "e8ff49d3-16a0-400f-c0b5-bd2de13ba474",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded labels: [2 2 2 ... 1 1 1]\n",
      "Mapping of encoded labels to original labels:\n",
      "0: Negative\n",
      "1: Neutrally\n",
      "2: Positive\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "Message = data['Message'].values\n",
    "Sentiment = data['Sentiment'].values\n",
    "\n",
    "# ใช้สำหรับแปลงข้อความเป็นเวกเตอร์ของจำนวนคำที่ปรากฏในข้อความนั้น ๆ\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(Message).toarray()\n",
    "\n",
    "# Encoding labels\n",
    "encoder = LabelEncoder()\n",
    "encoded_labels = encoder.fit_transform(Sentiment)\n",
    "\n",
    "print(\"Encoded labels:\", encoded_labels)\n",
    "print(\"Mapping of encoded labels to original labels:\")\n",
    "for label, original_label in enumerate(encoder.classes_):\n",
    "    print(f\"{label}: {original_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "wpOS5YMc8oyn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# แบ่งข้อมูลเป็นชุดฝึกและชุดทดสอบ\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, encoded_labels, stratify=encoded_labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "-izANEFsZr5r",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ใช้สำหรับการค้นหาค่าพารามิเตอร์ที่เหมาะสมที่สุดสำหรับโมเดล SVM\n",
    "def grid_search_hyperparameters(X_train, y_train, X_test, y_test, hyperparameters):\n",
    "    best_accuracy = 0\n",
    "    best_hyperparameters = None\n",
    "\n",
    "    for params in hyperparameters:\n",
    "        learning_rate, lambda_param, num_epochs, batch_size = params\n",
    "\n",
    "        # Initialize and train the SVM model with the current hyperparameters\n",
    "        svm_model = SVM(learning_rate=learning_rate, lambda_param=lambda_param, num_epochs=num_epochs, batch_size=batch_size)\n",
    "        svm_model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        predictions = svm_model.predict(X_test)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "        # Update the best hyperparameters if the current ones perform better\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_hyperparameters = params\n",
    "\n",
    "    return best_hyperparameters, best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "53lHIglj95BL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self, learning_rate=0.0001, lambda_param=0.01, num_epochs=500, batch_size=32):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lambda_param = lambda_param\n",
    "        self.num_epochs = num_epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.num_classes = None\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.num_classes = len(np.unique(y))\n",
    "        self.weights = np.zeros((num_features, self.num_classes))\n",
    "        self.bias = np.zeros(self.num_classes)\n",
    "\n",
    "        for _ in range(self.num_epochs):\n",
    "            for batch_start in range(0, num_samples, self.batch_size):\n",
    "                batch_end = min(batch_start + self.batch_size, num_samples)\n",
    "                X_batch = X[batch_start:batch_end]\n",
    "                y_batch = y[batch_start:batch_end]\n",
    "\n",
    "                for idx, x_i in enumerate(X_batch):\n",
    "                    for class_idx in range(self.num_classes):\n",
    "                        y_val = 1 if y_batch[idx] == class_idx else -1\n",
    "                        condition = y_val * (np.dot(x_i, self.weights[:, class_idx]) - self.bias[class_idx]) >= 1\n",
    "                        if not condition:\n",
    "                            self.weights[:, class_idx] -= self.learning_rate * (2 * self.lambda_param * self.weights[:, class_idx] - np.dot(x_i, y_val))\n",
    "                            self.bias[class_idx] -= self.learning_rate * y_val\n",
    "\n",
    "    def predict(self, X):\n",
    "        approx = np.dot(X, self.weights) - self.bias\n",
    "        return np.argmax(approx, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "QuG77DiR-cJT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the SVM model\n",
    "clf = SVM()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "jjeXqPnbGWDg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g24b0P3qGAPI",
    "outputId": "15d599ea-700c-4da7-e791-b0f47797fecc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6911111111111111\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.61      0.67       150\n",
      "           1       0.65      0.67      0.66       150\n",
      "           2       0.70      0.79      0.74       150\n",
      "\n",
      "    accuracy                           0.69       450\n",
      "   macro avg       0.69      0.69      0.69       450\n",
      "weighted avg       0.69      0.69      0.69       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "# Print classification report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xgvfvQaZT_Bu",
    "outputId": "f00fb518-634f-4d93-db75-3b49bbef2eaf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is classified as: Negative\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the input text\n",
    "test_text_processed = remove_duplicate_chars(\"การทำงานของร้านค้าช้ามาก กว่าจะส่งของช้ามากๆ\")\n",
    "\n",
    "# Transform the preprocessed text into TF-IDF numerical features\n",
    "test_text_tfidf = vectorizer.transform([test_text_processed]).toarray()\n",
    "\n",
    "# Predict the sentiment label using the trained SVM classifier\n",
    "predicted_label = clf.predict(test_text_tfidf)\n",
    "\n",
    "# Mapping of predicted label to sentiment\n",
    "sentiment_mapping = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
    "\n",
    "# Print the classification result\n",
    "print(\"The text is classified as:\", sentiment_mapping[predicted_label[0]])\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
